{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA (latent Dirichlet Allocation) attempts to assign documents to topics based on the probability of a term being in the topic and the topic being in the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space'\n",
    "]\n",
    "groups = fetch_20newsgroups(subset='all', categories=categories)\n",
    "labels = groups.target\n",
    "label_names = groups.target_names\n",
    "def is_letter_only(word):\n",
    "    for char in word:\n",
    "        if not char.isalpha():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "from nltk.corpus import names\n",
    "all_names = set(names.words())\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data_cleaned = []\n",
    "for doc in groups.data:\n",
    "    doc = doc.lower()\n",
    "    doc_cleaned = ' '.join(lemmatizer.lemmatize(word) for word in doc.split() if is_letter_only(word) and word not in all_names)\n",
    "    data_cleaned.append(doc_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a countvector (we can only use a countvector, not tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vector = CountVectorizer(stop_words=\"english\", max_features=None, max_df=0.5, min_df=2)\n",
    "data = count_vector.fit_transform(data_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the LDA object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "t = 20\n",
    "lda = LatentDirichletAllocation(n_components=t, learning_method='batch', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=20, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic-term rank can be obtained from components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05     , 2.05     , 2.05     , ..., 0.05     , 0.05     ,\n",
       "        0.05     ],\n",
       "       [0.05     , 0.05     , 0.05     , ..., 0.05     , 0.05     ,\n",
       "        0.05     ],\n",
       "       [0.05     , 0.05     , 0.05     , ..., 4.0336285, 0.05     ,\n",
       "        0.05     ],\n",
       "       ...,\n",
       "       [0.05     , 0.05     , 0.05     , ..., 0.05     , 0.05     ,\n",
       "        0.05     ],\n",
       "       [0.05     , 0.05     , 0.05     , ..., 0.05     , 0.05     ,\n",
       "        0.05     ],\n",
       "       [0.05     , 0.05     , 0.05     , ..., 0.05     , 0.05     ,\n",
       "        3.05     ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print top 10 terms for each rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0:\n",
      "atheist doe ha believe say jesus people christian wa god\n",
      "Topic: 1:\n",
      "moment just adobe want know ha wa hacker article radius\n",
      "Topic: 2:\n",
      "center point ha wa available research computer data graphic hst\n",
      "Topic: 3:\n",
      "objective argument just thing doe people wa think say article\n",
      "Topic: 4:\n",
      "time like brian ha good life want know just wa\n",
      "Topic: 5:\n",
      "computer graphic think know need university just article wa like\n",
      "Topic: 6:\n",
      "free program color doe use version gif jpeg file image\n",
      "Topic: 7:\n",
      "gamma ray did know university ha just like article wa\n",
      "Topic: 8:\n",
      "tool ha processing using data software color program bit image\n",
      "Topic: 9:\n",
      "apr men know ha think woman just university article wa\n",
      "Topic: 10:\n",
      "jpl propulsion mission april mar jet command data spacecraft wa\n",
      "Topic: 11:\n",
      "russian like ha university redesign point option article space station\n",
      "Topic: 12:\n",
      "ha van book star material physicist universe physical theory wa\n",
      "Topic: 13:\n",
      "bank doe book law wa article rushdie muslim islam islamic\n",
      "Topic: 14:\n",
      "think gopher routine point polygon book university article know wa\n",
      "Topic: 15:\n",
      "ha rocket new lunar mission satellite shuttle nasa launch space\n",
      "Topic: 16:\n",
      "want right article ha make like just think people wa\n",
      "Topic: 17:\n",
      "just light space henry wa like zoology sky article toronto\n",
      "Topic: 18:\n",
      "comet venus solar moon orbit planet earth probe ha wa\n",
      "Topic: 19:\n",
      "site format image mail program available ftp send file graphic\n"
     ]
    }
   ],
   "source": [
    "terms = count_vector.get_feature_names()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(\"Topic: {}:\".format(topic_idx))\n",
    "    print(\" \".join([terms[i] for i in topic.argsort()[-10:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
