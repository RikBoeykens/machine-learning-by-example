{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and clean newsgroup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space'\n",
    "]\n",
    "groups = fetch_20newsgroups(subset='all', categories=categories)\n",
    "labels = groups.target\n",
    "label_names = groups.target_names\n",
    "def is_letter_only(word):\n",
    "    for char in word:\n",
    "        if not char.isalpha():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "from nltk.corpus import names\n",
    "all_names = set(names.words())\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data_cleaned = []\n",
    "for doc in groups.data:\n",
    "    doc = doc.lower()\n",
    "    doc_cleaned = ' '.join(lemmatizer.lemmatize(word) for word in doc.split() if is_letter_only(word) and word not in all_names)\n",
    "    data_cleaned.append(doc_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert cleaned data into count vectors. We use minimum and maximum document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vector = CountVectorizer(stop_words=\"english\", max_features=None, max_df=0.5, min_df=2)\n",
    "data = count_vector.fit_transform(data_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster data into four groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=4, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=42, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check sizes of resulting clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 3360, 0: 17, 1: 7, 2: 3})\n"
     ]
    }
   ],
   "source": [
    "clusters = kmeans.labels_\n",
    "from collections import Counter\n",
    "print(Counter(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that most samples congested into one big cluster (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfIdfVectorizer diminishes the weight of common terms occuring frequently, qnd emphasizes terms that rarely occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 1480, 0: 782, 1: 615, 2: 510})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vector = TfidfVectorizer(stop_words='english', max_features=None, max_df=0.5, min_df=2)\n",
    "data = tfidf_vector.fit_transform(data_cleaned)\n",
    "kmeans.fit(data)\n",
    "clusters = kmeans.labels_\n",
    "print(Counter(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine each cluster, what they contain and the top 10 terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_0: 782 samples\n",
      "comp.graphics: 733 samples\n",
      "sci.space: 44 samples\n",
      "alt.atheism: 4 samples\n",
      "talk.religion.misc: 1 samples\n",
      "Top 10 terms:\n",
      " computer need know thanks looking university program file graphic image\n",
      "cluster_1: 615 samples\n",
      "alt.atheism: 365 samples\n",
      "talk.religion.misc: 247 samples\n",
      "comp.graphics: 2 samples\n",
      "sci.space: 1 samples\n",
      "Top 10 terms:\n",
      " article moral think morality jesus people wa say christian god\n",
      "cluster_2: 510 samples\n",
      "sci.space: 508 samples\n",
      "alt.atheism: 1 samples\n",
      "comp.graphics: 1 samples\n",
      "Top 10 terms:\n",
      " just zoology moon hst nasa mission wa launch shuttle space\n",
      "cluster_3: 1480 samples\n",
      "sci.space: 434 samples\n",
      "alt.atheism: 429 samples\n",
      "talk.religion.misc: 380 samples\n",
      "comp.graphics: 237 samples\n",
      "Top 10 terms:\n",
      " new people think know like ha just university article wa\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "cluster_label = {i: labels[np.where(clusters == i)] for i in range(k)}\n",
    "terms = tfidf_vector.get_feature_names()\n",
    "centroids = kmeans.cluster_centers_\n",
    "for cluster, index_list in cluster_label.items():\n",
    "    counter = Counter(cluster_label[cluster])\n",
    "    print('cluster_{}: {} samples'.format(cluster, len(index_list)))\n",
    "    for label_index, count in sorted(counter.items(), key = lambda x: x[1], reverse=True):\n",
    "        print('{}: {} samples'.format(label_names[label_index], count))\n",
    "    print('Top 10 terms:')\n",
    "    for ind in centroids[cluster].argsort()[-10:]:\n",
    "        print(' %s' % terms[ind], end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
