{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "1500\n",
      "5172\n",
      "5172\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "corpus_path = 'C:/Users/Rik/Documents/corpus/'\n",
    "emails, labels = [], []\n",
    "def readFilesForFolder(folder_path, is_spam):\n",
    "    file_path = corpus_path + 'enron1/' + folder_path\n",
    "    for filename in glob.glob(os.path.join(file_path, '*.txt')):\n",
    "        with open(filename, 'r', encoding=\"ISO-8859-1\") as infile:\n",
    "            emails.append(infile.read())\n",
    "            labels.append(is_spam)\n",
    "readFilesForFolder('spam', 1)\n",
    "print(len(emails))\n",
    "print(len(labels))\n",
    "readFilesForFolder('ham', 0)\n",
    "print(len(emails))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_email(email):\n",
    "    doc = nlp(email)\n",
    "    return \" \".join([token.lemma_.lower() for token in doc if token.is_alpha and not token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_emails = [\n",
    "    clean_email(email) for email in emails\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a 10-fold generator to divide data into chunks with preserved class fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "k = 10\n",
    "k_fold = StratifiedKFold(n_splits=k, random_state=42)\n",
    "cleaned_emails_np = np.array(cleaned_emails)\n",
    "labels_np = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_features: n most frequent terms to use as feature space  \n",
    "alpha: smoothing factor  \n",
    "fit_prior: use prior tailored to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_option = [2000, 8000, None]\n",
    "smoothing_factor_option = [0.5, 1.0, 2.0, 4.0]\n",
    "fit_prior_option = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def run_kfold_multinomial(max_features_option, smoothing_factor_option, fit_prior_option):\n",
    "    auc_record = []\n",
    "    for train_indices, test_indices in k_fold.split(cleaned_emails, labels):\n",
    "        X_train, X_test = cleaned_emails_np[train_indices], cleaned_emails_np[test_indices]\n",
    "        Y_train, Y_test = labels_np[train_indices], labels_np[test_indices]\n",
    "        for max_features in max_features_option:\n",
    "            cv = CountVectorizer(stop_words='english', max_features = max_features, max_df = 0.5, min_df=2)\n",
    "            term_docs_train = cv.fit_transform(X_train)\n",
    "            term_docs_test = cv.transform(X_test)\n",
    "            for alpha in smoothing_factor_option:\n",
    "                for fit_prior in fit_prior_option:\n",
    "                    clf = MultinomialNB(alpha = alpha, fit_prior = fit_prior)\n",
    "                    clf.fit(term_docs_train, Y_train)\n",
    "                    prediction_prob = clf.predict_proba(term_docs_test)\n",
    "                    pos_prob = prediction_prob[:, 1]\n",
    "                    auc = roc_auc_score(Y_test, pos_prob)\n",
    "                    auc_record.append({\n",
    "                        'max_features': max_features,\n",
    "                        'smoothing': alpha,\n",
    "                        'fit_prior': fit_prior,\n",
    "                        'auc': auc\n",
    "                    })\n",
    "    return auc_record\n",
    "auc_record = run_kfold_multinomial(max_features_option, smoothing_factor_option, fit_prior_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 4.0 False 0.9891564832365832\n",
      "-1.0 4.0 True 0.9891174352367413\n",
      "-1.0 0.5 False 0.9883294090352643\n",
      "-1.0 0.5 True 0.9882840105832642\n",
      "-1.0 2.0 True 0.9881240744580027\n",
      "-1.0 2.0 False 0.9880967820755833\n",
      "-1.0 1.0 False 0.9880398303913438\n",
      "-1.0 1.0 True 0.98796088042491\n",
      "8000.0 0.5 True 0.9850525683173398\n",
      "8000.0 0.5 False 0.9850373622793509\n",
      "8000.0 1.0 True 0.9840703708091458\n",
      "8000.0 1.0 False 0.9840158551514435\n",
      "8000.0 2.0 False 0.9833223304900682\n",
      "8000.0 2.0 True 0.983278753504719\n",
      "8000.0 4.0 True 0.9831593610551673\n",
      "8000.0 4.0 False 0.9830566900643684\n",
      "2000.0 0.5 True 0.9742725585436164\n",
      "2000.0 0.5 False 0.9742134916873988\n",
      "2000.0 1.0 True 0.9730513441337914\n",
      "2000.0 1.0 False 0.9729806253208547\n",
      "2000.0 2.0 True 0.9714262429411995\n",
      "2000.0 2.0 False 0.9713636763021757\n",
      "2000.0 4.0 True 0.9692736765983494\n",
      "2000.0 4.0 False 0.9690602342731903\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def print_results(auc_record):\n",
    "    for auc_run in sorted([\n",
    "        {\n",
    "            'max_features': key[0],\n",
    "            'smoothing': key[1],\n",
    "            'fit_prior': key[2],\n",
    "            'auc': np.mean(group['auc'])\n",
    "        }\n",
    "        for key, group in pd.DataFrame(auc_record).fillna(-1).groupby(['max_features', 'smoothing', 'fit_prior'])\n",
    "    ], key = lambda auc_run: auc_run['auc'], reverse = True):\n",
    "        print(auc_run['max_features'], auc_run['smoothing'], auc_run['fit_prior'], auc_run['auc'])\n",
    "    \n",
    "print_results(auc_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 20.0 False 0.9935004294514869\n",
      "-1 20.0 True 0.9935004294514869\n",
      "-1 16.0 True 0.9934130262014769\n",
      "-1 16.0 False 0.9933749950637759\n",
      "-1 32.0 False 0.9932311041345813\n",
      "-1 32.0 True 0.9932301958693678\n",
      "-1 10.0 False 0.9923001273545788\n",
      "-1 10.0 True 0.9922819867314299\n",
      "-1 4.0 False 0.9891564832365832\n",
      "-1 4.0 True 0.9891174352367413\n"
     ]
    }
   ],
   "source": [
    "max_features_option = [None]\n",
    "smoothing_factor_option = [4.0, 10, 16, 20, 32]\n",
    "fit_prior_option = [True, False]\n",
    "print_results(run_kfold_multinomial(max_features_option, smoothing_factor_option, fit_prior_option))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
